æ³¨æ„åˆ°æ–¹æ³• `retire_gc_alloc_region` æ˜¯å°† old region å’Œ survivor region åŠ å…¥åˆ° `G1CollectedHeap` å¯¹åº”çš„ set ä¸­ï¼Œè€Œä¸æ˜¯ csetã€‚

ä¸ºäº†è¿…é€Ÿæ‰¾åˆ°å…¥å£å‡½æ•°åœ¨æ–¹æ³• `retire_gc_alloc_region`åŠ ç‚¹æ—¥å¿—ã€‚

```cpp
void G1CollectedHeap::retire_gc_alloc_region(G1HeapRegion* alloc_region, size_t allocated_bytes, G1HeapRegionAttr dest) {
  assert(dest.is_young(), "retire_gc_alloc_region (%d)", dest.type())

  _bytes_used_during_gc += allocated_bytes;
  if (dest.is_old()) { old_set_add(alloc_region);
  } else { _survivor.add_used_bytes(allocated_bytes); }

  bool const during_im = collector_state()->in_concurrent_start_gc();
  if (during_im && allocated_bytes > 0) {
    _cm->add_root_region(alloc_region); //æ³¨æ„åé¢å¹¶å‘æ ‡è®°æ—¶ä¼šè¯´åˆ°
  }
}
```

ä»æ—¥å¿—æ–‡ä»¶ä¸­å¯ä»¥çœ‹åˆ°æŠ¥é”™çš„è°ƒç”¨æ ˆï¼Œç¡®å®æ˜¯åœ¨ GC æ”¶å°¾æ—¶å°† region åŠ å…¥åˆ° cset ä¸­ã€‚

<image src="/assets/ygc-pre/g1-ygc-pre-cset-retire-gc-alloc-region.png" width="80%">



æœ€è¿‘åœ¨çœ‹ G1 åƒåœ¾æ”¶é›†å™¨çš„ç›¸å…³ä»£ç ï¼Œå°†ç†è§£å†…å®¹æ•´ç†æˆæ–‡ç« è¾“å‡ºã€‚

æœ€å¼€å§‹åœ¨æ˜é‡‘æ›´æ–°ï¼Œåæ¥å‘ç°ä¸å¥½ç®¡ç†ã€å›¾ç‰‡æœ‰æ°´å°ã€å‘å¸ƒéœ€è¦è¢«å®¡æ ¸ç­‰åŸå› ï¼Œé€æ­¥è¿ç§»åˆ° githubã€‚

æ–‡ç« åœ°å€ä¸ºï¼šhttps://yoa1226.github.io

è§‰å¾—æœ‰ç”¨çš„æœ‹å‹ç‚¹ä¸ªğŸŒŸğŸŒŸğŸ˜˜

https://github.com/yoa1226/yoa1226.github.io


```cpp
bool G1Policy::need_to_start_conc_mark(const char* source, size_t alloc_word_size) {
  if (about_to_start_mixed_phase()) {
    return false;
  }

  size_t marking_initiating_used_threshold = _ihop_control->get_conc_mark_start_threshold();

  size_t cur_used_bytes = _g1h->non_young_capacity_bytes();
  size_t alloc_byte_size = alloc_word_size * HeapWordSize;
  size_t marking_request_bytes = cur_used_bytes + alloc_byte_size;

  bool result = false;
  if (marking_request_bytes > marking_initiating_used_threshold) {
    result = collector_state()->in_young_only_phase();
    log_debug(gc, ergo, ihop)("%s occupancy: " SIZE_FORMAT "B allocation request: " SIZE_FORMAT "B threshold: " SIZE_FORMAT "B (%1.2f) source: %s",
                              result ? "Request concurrent cycle initiation (occupancy higher than threshold)" : "Do not request concurrent cycle initiation (still doing mixed collections)",
                              cur_used_bytes, alloc_byte_size, marking_initiating_used_threshold, (double) marking_initiating_used_threshold / _g1h->capacity() * 100, source);
  }
  return result;
}

void G1Policy::maybe_start_marking() {
  if (need_to_start_conc_mark("end of GC")) {
    // Note: this might have already been set, if during the last
    // pause we decided to start a cycle but at the beginning of
    // this pause we decided to postpone it. That's OK.
    collector_state()->set_initiate_conc_mark_if_possible(true);
  }
}


bool const during_im = collector_state()->in_concurrent_start_gc();
  if (during_im && allocated_bytes > 0) {
    _cm->add_root_region(alloc_region);
  }

  G1EvacuationRootClosures* res = nullptr;
if (g1h->collector_state()->in_concurrent_start_gc()) {
  if (ClassUnloadingWithConcurrentMark) {
    res = new G1ConcurrentStartMarkClosures<false>(g1h, pss);
  } else {
    res = new G1ConcurrentStartMarkClosures<true>(g1h, pss);
  }
} else {
  res = new G1EvacuationClosures(g1h, pss, process_only_dirty_klasses);
}


  if (collector_state()->in_concurrent_start_gc()) {
    concurrent_mark()->pre_concurrent_start(_gc_cause);
  }


  void G1YoungCollector::enqueue_candidates_as_root_regions() {
  assert(collector_state()->in_concurrent_start_gc(), "must be");

  G1CollectionSetCandidates* candidates = collection_set()->candidates();
  for (G1HeapRegion* r : *candidates) {
    _g1h->concurrent_mark()->add_root_region(r);
  }
}

 EagerlyReclaimHumongousObjectsTask() 
 //å¤„ç†å¤§å¯¹è±¡


```

